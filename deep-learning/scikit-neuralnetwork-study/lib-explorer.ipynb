{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Convolution, FastVectorSpace, Layer, MultiLayerPerceptron\n",
    "from sknn.mlp import NeuralNetwork, Regressor, SparseDesignMatrix\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def XOR(n):\n",
    "    # 1000개의 데이터를 생성\n",
    "    X = [[randint(0, 1), randint(0, 1)] for _ in range(n)]\n",
    "    y = []\n",
    "    for a, b in X:\n",
    "        if a == b:\n",
    "            y.append([0])\n",
    "        else:\n",
    "            y.append([1])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features, labels = XOR(n=1000)\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of training set 700 rows, 2 columns\n",
      "the shape of test set 300 rows, 2 columns\n",
      "the range of training set : 0 ~ 1\n",
      "the range of test set : 0 ~ 1\n"
     ]
    }
   ],
   "source": [
    "print \"the shape of training set %s rows, %s columns\" %(trainX.shape[0], trainX.shape[1])\n",
    "print \"the shape of test set %s rows, %s columns\" %(testX.shape[0], testX.shape[1])\n",
    "print \"the range of training set : %s ~ %s\" %(trainX.min(),trainX.max())\n",
    "print \"the range of test set : %s ~ %s\" %(testX.min(),testX.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 1.0\n",
      "classification report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       148\n",
      "          1       1.00      1.00      1.00       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Regression Example\n",
    "nn = Regressor(\n",
    "    layers=[\n",
    "        Layer(\"Rectifier\", units=100),\n",
    "        Layer(\"Linear\")],\n",
    "    learning_rate=0.2,\n",
    "    n_iter=100)\n",
    "nn.fit(trainX, trainY)\n",
    "\n",
    "# compute the predictions for the test data and show a classification report\n",
    "preds = nn.predict(testX)\n",
    "preds = preds.astype('int64')\n",
    "\n",
    "print \"accuracy score : %s\" %(accuracy_score(testY, preds))\n",
    "print \"classification report : \"\n",
    "print classification_report(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 1.0\n",
      "classification report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       148\n",
      "          1       1.00      1.00      1.00       152\n",
      "\n",
      "avg / total       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification \n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Maxout\", units=100, pieces=2),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=25)\n",
    "nn.fit(trainX, trainY)\n",
    "\n",
    "# compute the predictions for the test data and show a classification report\n",
    "preds = nn.predict(testX)\n",
    "preds = preds.astype('int64')\n",
    "\n",
    "print \"accuracy score : %s\" %(accuracy_score(testY, preds))\n",
    "print \"classification report : \"\n",
    "print classification_report(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = datasets.fetch_mldata(\"MNIST Original\", data_home=\".\")\n",
    "\n",
    "features = np.array(dataset.data, 'float32') / 255\n",
    "labels = np.array(dataset.target, 'int')\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of training set 49000 rows, 1 columns\n",
      "the shape of test set 21000 rows, 1 columns\n",
      "the range of training set : 0.0 ~ 1.0\n",
      "the range of test set : 0.0 ~ 1.0\n"
     ]
    }
   ],
   "source": [
    "print \"the shape of training set %s rows, %s columns\" %(trainX.shape[0], trainX.shape[1])\n",
    "print \"the shape of test set %s rows, %s columns\" %(testX.shape[0], testX.shape[1])\n",
    "print \"the range of training set : %s ~ %s\" %(trainX.min(),trainX.max())\n",
    "print \"the range of test set : %s ~ %s\" %(testX.min(),testX.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.97119047619\n",
      "classification report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      2026\n",
      "          1       0.98      0.99      0.98      2331\n",
      "          2       0.97      0.97      0.97      2128\n",
      "          3       0.97      0.97      0.97      2183\n",
      "          4       0.94      0.98      0.96      1976\n",
      "          5       0.98      0.97      0.97      1905\n",
      "          6       0.98      0.98      0.98      2085\n",
      "          7       0.96      0.98      0.97      2181\n",
      "          8       0.98      0.95      0.97      2031\n",
      "          9       0.98      0.92      0.95      2154\n",
      "\n",
      "avg / total       0.97      0.97      0.97     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convolution \n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Convolution(\"Rectifier\", channels=9, kernel_shape=(3,3), border_mode='full'),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.02,\n",
    "    n_iter=10)\n",
    "nn.fit(trainX, trainY)\n",
    "\n",
    "# compute the predictions for the test data and show a classification report\n",
    "preds = nn.predict(testX)\n",
    "\n",
    "print \"accuracy score : %s\" %(accuracy_score(testY, preds))\n",
    "print \"classification report : \"\n",
    "print classification_report(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None,\n",
       "       estimator=Regressor(batch_size=1, debug=False, dropout_rate=None, f_stable=0.001,\n",
       "     hidden0=<sknn.nn.Layer `Sigmoid`: name=u'hidden0', units=10>,\n",
       "     hidden1=<sknn.nn.Layer `Sigmoid`: name=u'hidden1', units=10>,\n",
       "     layers=[<sknn.nn.Layer `Sigmoid`: name=u'hidden0', units=10>, <sknn.nn.Layer `S...state=None,\n",
       "     regularize=None, valid_set=None, valid_size=0.0, verbose=1,\n",
       "     weight_decay=None),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'n_iter': [5], 'hidden0__units': [20, 30], 'learning_rate': [0.05, 0.01], 'hidden1__units': [20, 30], 'hidden1__type': ['Sigmoid', 'Tanh'], 'hidden0__type': ['Sigmoid', 'Tanh']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "# \"Rectifier\", \"Sigmoid\", \"Tanh\", \"Maxout\", \"Linear\", \"Softmax\", \"Gaussian\"\n",
    "features, labels = XOR(n=100)\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "nn = Regressor(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=10),# 첫번째 히든레이어\n",
    "        Layer(\"Sigmoid\", units=10),# 두번째 히든레이어\n",
    "        Layer(\"Linear\")], # 아웃풋 레이어\n",
    "    verbose=1)\n",
    "\n",
    "gs = GridSearchCV(nn, param_grid={\n",
    "    'learning_rate': [0.05, 0.01],\n",
    "    'n_iter' : [5],\n",
    "    'hidden0__units': [20, 30],\n",
    "    'hidden0__type': [\"Sigmoid\", \"Tanh\"], # 첫번째 히든레이어\n",
    "    'hidden1__units': [20, 30],\n",
    "    'hidden1__type': [\"Sigmoid\", \"Tanh\"]}) # 두번째 히든레이어\n",
    "gs.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_iter': 5, 'hidden0__units': 30, 'learning_rate': 0.05, 'hidden1__units': 30, 'hidden1__type': 'Sigmoid', 'hidden0__type': 'Tanh'}\n",
      "\n",
      "Regressor(batch_size=1, debug=False, dropout_rate=None, f_stable=0.001,\n",
      "     hidden0=<sknn.nn.Layer `Tanh`: name=u'hidden0', units=30>,\n",
      "     hidden1=<sknn.nn.Layer `Sigmoid`: name=u'hidden1', units=30>,\n",
      "     layers=[<sknn.nn.Layer `Tanh`: name=u'hidden0', units=30>, <sknn.nn.Layer `Sigmoid`: name=u'hidden1', units=30>, <sknn.nn.Layer `Linear`: name=u'output', units=1>],\n",
      "     learning_momentum=0.9, learning_rate=0.05, learning_rule=u'sgd',\n",
      "     loss_type=u'mse', n_iter=5, n_stable=50,\n",
      "     output=<sknn.nn.Layer `Linear`: name=u'output', units=1>,\n",
      "     random_state=None, regularize=None, valid_set=None, valid_size=0.0,\n",
      "     verbose=1, weight_decay=None)\n"
     ]
    }
   ],
   "source": [
    "print gs.best_params_\n",
    "print \n",
    "print gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.566666666667\n",
      "classification report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      1.00      0.72        17\n",
      "          1       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.32      0.57      0.41        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the predictions for the test data and show a classification report\n",
    "preds = gs.predict(testX)\n",
    "preds = preds.astype('int64')\n",
    "\n",
    "\n",
    "print \"accuracy score : %s\" %(accuracy_score(testY, preds))\n",
    "print \"classification report : \"\n",
    "print classification_report(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.966476190476\n",
      "classification report : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      2119\n",
      "          1       0.98      0.99      0.99      2382\n",
      "          2       0.97      0.93      0.95      2068\n",
      "          3       0.94      0.97      0.95      2091\n",
      "          4       0.97      0.98      0.97      2023\n",
      "          5       0.96      0.96      0.96      1909\n",
      "          6       0.98      0.98      0.98      2052\n",
      "          7       0.96      0.97      0.97      2194\n",
      "          8       0.97      0.95      0.96      2024\n",
      "          9       0.96      0.95      0.95      2138\n",
      "\n",
      "avg / total       0.97      0.97      0.97     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.fetch_mldata(\"MNIST Original\", data_home=\".\")\n",
    "\n",
    "features = np.array(dataset.data, 'float32') / 255\n",
    "labels = np.array(dataset.target, 'int')\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "\n",
    "# Convolution \n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Convolution(\"Rectifier\", channels=9, kernel_shape=(3,3), border_mode='full'),\n",
    "        Convolution(\"Rectifier\", channels=9, kernel_shape=(2,2), border_mode='full'),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.02,\n",
    "    n_iter=10)\n",
    "nn.fit(trainX, trainY)\n",
    "\n",
    "# compute the predictions for the test data and show a classification report\n",
    "preds = nn.predict(testX)\n",
    "\n",
    "print \"accuracy score : %s\" %(accuracy_score(testY, preds))\n",
    "print \"classification report : \"\n",
    "print classification_report(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(batch_size=1, debug=False, dropout_rate=None, f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Convolution `Rectifier`: channels=9, name=u'hidden0', kernel_shape=(3, 3), kernel_stride=(1, 1), pool_shape=(1, 1), border_mode='full'>,\n",
       "      hidden1=<sknn.nn.Convolution `Rectifier`: channels=9, name=u'hidden1', kernel_shape=(2, 2), kernel_stride=(1, 1), pool_shape=(1, 1), border_mode='full'>,\n",
       "      layers=[<sknn.nn.Convolution `Rectifier`: channels=9, name=u'hidden0', kernel_shape=(3, 3), kernel_stride=(1, 1), pool_shape=(1, 1), border_mode='full'>, <sknn.nn.Convolution `Rectifier`: channels=9, name=u'hidden1', kernel_shape=(2, 2), kernel_stride=(1, 1), pool_shape=(1, 1), border_mode='full'>, <sknn.nn.Layer `Softmax`: name=u'output', units=10>],\n",
       "      learning_momentum=0.9, learning_rate=0.02, learning_rule=u'sgd',\n",
       "      loss_type=u'mse', n_iter=10, n_stable=50,\n",
       "      output=<sknn.nn.Layer `Softmax`: name=u'output', units=10>,\n",
       "      random_state=None, regularize=None, valid_set=None, valid_size=0.0,\n",
       "      verbose=False, weight_decay=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, ..., 8, 9, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sknn.ae.AutoEncoder at 0x10aeca890>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sknn.ae import AutoEncoder, Layer\n",
    "# 위에서와 Layer가 이름이 겹치므로 주의\n",
    "\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\", data_home=\".\")\n",
    "\n",
    "features = np.array(dataset.data, 'float32') / 255\n",
    "labels = np.array(dataset.target, 'int')\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "# Regression Example\n",
    "nn = AutoEncoder(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=100),\n",
    "        Layer(\"Tanh\", units=10)],\n",
    "    learning_rate=0.2,\n",
    "    n_iter=10)\n",
    "nn.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<sknn.nn.Layer `autoencoder`: tied_weights=True, cost=u'msre', corruption_level=0.5, name=u'hidden0', units=100, activation='sigmoid'>, <sknn.nn.Layer `autoencoder`: tied_weights=True, cost=u'msre', corruption_level=0.5, name=u'output', units=10, activation='tanh'>]\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print nn.layers\n",
    "print nn.f_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 784)\n",
      "(21000, 10)\n"
     ]
    }
   ],
   "source": [
    "print testX.shape\n",
    "print nn.transform(testX).shape # \"Tanh\", units=10 이라서 아웃풋이 10으로 나온거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ...,  1.  1.  1.]\n",
      "95101\n"
     ]
    }
   ],
   "source": [
    "print np.unique(nn.transform(testX))\n",
    "print len(np.unique(nn.transform(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0.9\n",
      "0.2\n",
      "sgd\n",
      "mse\n",
      "10\n",
      "50\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print nn.is_convolution\n",
    "print nn.learning_momentum\n",
    "print nn.learning_rate\n",
    "print nn.learning_rule\n",
    "print nn.loss_type\n",
    "print nn.n_iter\n",
    "print nn.n_stable\n",
    "print nn.random_state\n",
    "print nn.regularize\n",
    "print nn.valid_set\n",
    "print nn.weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3be35c3febc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# gs = GridSearchCV(nn, param_grid={\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dikien/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \"\"\"\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dikien/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                  \u001b[0;34m'of samples (%i) than data (X: %i samples)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                                  % (len(y), n_samples))\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dikien/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_check_cv\u001b[0;34m(cv, X, y, classifier, warn_mask)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneeds_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneeds_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dikien/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, indices, shuffle, random_state)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0;31m# the test split can be too big because we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# 왜 안될까?\n",
    "# Grid Search\n",
    "# \"Rectifier\", \"Sigmoid\", \"Tanh\", \"Maxout\", \"Linear\", \"Softmax\", \"Gaussian\"\n",
    "features, labels = XOR(n=100)\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Maxout\", units=100, pieces=2),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=5)\n",
    "\n",
    "# nn.fit(trainX, trainY)\n",
    "\n",
    "gs = GridSearchCV(nn, param_grid={'learning_rate': [0.05, 0.01]})\n",
    "gs.fit(trainX, trainY)\n",
    "\n",
    "# gs = GridSearchCV(nn, param_grid={\n",
    "#     'learning_rate': [0.05, 0.01],\n",
    "#     'n_iter' : [5],\n",
    "#     'pieces' : [2]}) # 두번째 히든레이어\n",
    "# gs.fit(trainX, trainY)\n",
    "\n",
    "# # compute the predictions for the test data and show a classification report\n",
    "# preds = gs.predict(testX)\n",
    "# preds = preds.astype('int64')\n",
    "\n",
    "\n",
    "# print \"accuracy score : %s\" %(accuracy_score(testY, preds))\n",
    "# print \"classification report : \"\n",
    "# print classification_report(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print trainY.dtype\n",
    "print testY.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
