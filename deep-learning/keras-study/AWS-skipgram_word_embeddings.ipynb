{"nbformat_minor": 0, "cells": [{"execution_count": 1, "cell_type": "code", "source": "import numpy as np\nimport theano\nimport six.moves.cPickle\nimport os, re, json\n\nfrom keras.preprocessing import sequence, text\nfrom keras.optimizers import SGD, RMSprop, Adagrad\nfrom keras.utils import np_utils, generic_utils\nfrom keras.models import Sequential\nfrom keras.layers.embeddings import WordContextProduct, Embedding\nfrom six.moves import range\nfrom six.moves import zip", "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using gpu device 0: GRID K520\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 2, "cell_type": "code", "source": "max_features = 50000 # vocabulary size: top 50,000 most common words in data\nskip_top = 100 # ignore top 100 most common words\nnb_epoch = 1\ndim_proj = 256 # embedding space dimension\n\nsave = True\nload_model = False\nload_tokenizer = True\ntrain_model = True\nsave_dir = os.path.expanduser(\"~/.keras/models\")\nmodel_load_fname = \"HN_skipgram_model.pkl\"\nmodel_save_fname = \"HN_skipgram_model.pkl\"\ntokenizer_fname = \"HN_tokenizer.pkl\"\n\ndata_path = os.path.expanduser(\"~/\")+\"HNCommentsAll.1perline.json\"", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "# text preprocessing utils\nhtml_tags = re.compile(r'<.*?>')\nto_replace = [('&#x27;', \"'\")]\nhex_tags = re.compile(r'&.*?;')\n\ndef clean_comment(comment):\n    c = str(comment.encode(\"utf-8\"))\n    c = html_tags.sub(' ', c)\n    for tag, char in to_replace:\n        c = c.replace(tag, char)\n    c = hex_tags.sub(' ', c)\n    return c\n\ndef text_generator(path=data_path):\n    f = open(path)\n    for i, l in enumerate(f):\n        comment_data = json.loads(l)\n        comment_text = comment_data[\"comment_text\"]\n        comment_text = clean_comment(comment_text)\n        if i % 10000 == 0:\n            print(i)\n        yield comment_text\n    f.close()", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 5, "cell_type": "code", "source": "# model management\nif load_tokenizer:\n    print('Load tokenizer...')\n    tokenizer = six.moves.cPickle.load(open(os.path.join(save_dir, tokenizer_fname), 'rb'))\nelse:\n    print(\"Fit tokenizer...\")\n    tokenizer = text.Tokenizer(nb_words=max_features)\n    tokenizer.fit_on_texts(text_generator())\n    if save:\n        print(\"Save tokenizer...\")\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        six.moves.cPickle.dump(tokenizer, open(os.path.join(save_dir, tokenizer_fname), \"wb\"))\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Fit tokenizer...\n0\n10000\n20000\n30000\n40000\n50000\n60000\n70000\n80000\n90000\n100000\n110000\n120000\n130000\n140000\n150000\n160000\n170000\n180000\n190000\n200000\n210000\n220000\n230000\n240000\n250000\n260000\n270000\n280000\n290000\n300000\n310000\n320000\n330000\n340000\n350000\n360000\n370000\n380000\n390000\n400000\n410000\n420000\n430000\n440000\n450000\n460000\n470000\n480000\n490000\n500000\n510000\n520000\n530000\n540000\n550000\n560000\n570000\n580000\n590000\n600000\n610000\n620000\n630000\n640000\n650000\n660000\n670000\n680000\n690000\n700000\n710000\n720000\n730000\n740000\n750000\n760000\n770000\n780000\n790000\n800000\n810000\n820000\n830000\n840000\n850000\n860000\n870000\n880000\n890000\n900000\n910000\n920000\n930000\n940000\n950000\n960000\n970000\n980000\n990000\n1000000\n1010000\n1020000\n1030000\n1040000\n1050000\n1060000\n1070000\n1080000\n1090000\n1100000\n1110000\n1120000\n1130000\n1140000\n1150000\n1160000\n1170000\n1180000\n1190000\n1200000\n1210000\n1220000\n1230000\n1240000\n1250000\n1260000\n1270000\n1280000\n1290000\n1300000\n1310000\n1320000\n1330000\n1340000\n1350000\n1360000\n1370000\n1380000\n1390000\n1400000\n1410000\n1420000\n1430000\n1440000\n1450000\n1460000\n1470000\n1480000\n1490000\n1500000\n1510000\n1520000\n1530000\n1540000\n1550000\n1560000\n1570000\n1580000\n1590000\n1600000\n1610000\n1620000\n1630000\n1640000\n1650000\n1660000\n1670000\n1680000\n1690000\n1700000\n1710000\n1720000\n1730000\n1740000\n1750000\n1760000\n1770000\n1780000\n1790000\n1800000\n1810000\n1820000\n1830000\n1840000\n1850000\n1860000\n1870000\n1880000\n1890000\n1900000\n1910000\n1920000\n1930000\n1940000\n1950000\n1960000\n1970000\n1980000\n1990000\n2000000\n2010000\n2020000\n2030000\n2040000\n2050000\n2060000\n2070000\n2080000\n2090000\n2100000\n2110000\n2120000\n2130000\n2140000\n2150000\n2160000\n2170000\n2180000\n2190000\n2200000\n2210000\n2220000\n2230000\n2240000\n2250000\n2260000\n2270000\n2280000\n2290000\n2300000\n2310000\n2320000\n2330000\n2340000\n2350000\n2360000\n2370000\n2380000\n2390000\n2400000\n2410000\n2420000\n2430000\n2440000\n2450000\n2460000\n2470000\n2480000\n2490000\n2500000\n2510000\n2520000\n2530000\n2540000\n2550000\n2560000\n2570000\n2580000\n2590000\n2600000\n2610000\n2620000\n2630000\n2640000\n2650000\n2660000\n2670000\n2680000\n2690000\n2700000\n2710000\n2720000\n2730000\n2740000\n2750000\n2760000\n2770000\n2780000\n2790000\n2800000\n2810000\n2820000\n2830000\n2840000\n2850000\n2860000\n2870000\n2880000\n2890000\n2900000\n2910000\n2920000\n2930000\n2940000\n2950000\n2960000\n2970000\n2980000\n2990000\n3000000\n3010000\n3020000\n3030000\n3040000\n3050000\n3060000\n3070000\n3080000\n3090000\n3100000\n3110000\n3120000\n3130000\n3140000\n3150000\n3160000\n3170000\n3180000\n3190000\n3200000\n3210000\n3220000\n3230000\n3240000\n3250000\n3260000\n3270000\n3280000\n3290000\n3300000\n3310000\n3320000\n3330000\n3340000\n3350000\n3360000\n3370000\n3380000\n3390000\n3400000\n3410000\n3420000\n3430000\n3440000\n3450000\n3460000\n3470000\n3480000\n3490000\n3500000\n3510000\n3520000\n3530000\n3540000\n3550000\n3560000\n3570000\n3580000\n3590000\n3600000\n3610000\n3620000\n3630000\n3640000\n3650000\n3660000\n3670000\n3680000\n3690000\n3700000\n3710000\n3720000\n3730000\n3740000\n3750000\n3760000\n3770000\n3780000\n3790000\n3800000\n3810000\n3820000\n3830000\n3840000\n3850000\n3860000\n3870000\n3880000\n3890000\n3900000\n3910000\n3920000\n3930000\n3940000\n3950000\n3960000\n3970000\n3980000\n3990000\n4000000\n4010000\n4020000\n4030000\n4040000\n4050000\n4060000\n4070000\n4080000\n4090000\n4100000\n4110000\n4120000\n4130000\n4140000\n4150000\n4160000\n4170000\n4180000\n4190000\n4200000\n4210000\n4220000\n4230000\n4240000\n4250000\n4260000\n4270000\n4280000\n4290000\n4300000\n4310000\n4320000\n4330000\n4340000\n4350000\n4360000\n4370000\n4380000\n4390000\n4400000\n4410000\n4420000\n4430000\n4440000\n4450000\n4460000\n4470000\n4480000\n4490000\n4500000\n4510000\n4520000\n4530000\n4540000\n4550000\n4560000\n4570000\n4580000\n4590000\n4600000\n4610000\n4620000\n4630000\n4640000\n4650000\n4660000\n4670000\n4680000\n4690000\n4700000\n4710000\n4720000\n4730000\n4740000\n4750000\n4760000\n4770000\n4780000\n4790000\n4800000\n4810000\n4820000\n4830000\n4840000\n4850000\n4860000\n4870000\n4880000\n4890000\n4900000\n4910000\n4920000\n4930000\n4940000\n4950000\n4960000\n4970000\n4980000\n4990000\n5000000\n5010000\n5020000\n5030000\n5040000\n5050000\n5060000\n5070000\n5080000\n5090000\n5100000\n5110000\n5120000\n5130000\n5140000\n5150000\n5160000\n5170000\n5180000\n5190000\n5200000\n5210000\n5220000\n5230000\n5240000\n5250000\n5260000\n5270000\n5280000\n5290000\n5300000\n5310000\n5320000\n5330000\n5340000\n5350000\n5360000\n5370000\n5380000\n5390000\n5400000\n5410000\n5420000\n5430000\n5440000\n5450000\n5460000\n5470000\n5480000\n5490000\n5500000\n5510000\n5520000\n5530000\n5540000\n5550000\n5560000\n5570000\n5580000\n5590000\n5600000\n5610000\n5620000\n5630000\n5640000\n5650000\n5660000\n5670000\n5680000\n5690000\n5700000\n5710000\n5720000\n5730000\n5740000\n5750000\n5760000\n5770000\n5780000\n5790000\n5800000\n5810000\n5820000\n5830000\n5840000\nSave tokenizer...\n"}], "metadata": {"scrolled": true, "collapsed": false, "trusted": true}}, {"execution_count": 8, "cell_type": "code", "source": "ls ~/.keras/models", "outputs": [{"output_type": "stream", "name": "stdout", "text": "HN_tokenizer.pkl\r\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 4, "cell_type": "code", "source": "tokenizer = six.moves.cPickle.load(open(os.path.join(save_dir, tokenizer_fname), 'rb'))", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 5, "cell_type": "code", "source": "tokenizer.document_count", "outputs": [{"execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "5845908"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "tokenizer.filters", "outputs": [{"execution_count": 6, "output_type": "execute_result", "data": {"text/plain": "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 12, "cell_type": "code", "source": "for key in tokenizer.word_counts.keys():\n    print key\n    print tokenizer.word_counts[key]\n    break", "outputs": [{"output_type": "stream", "name": "stdout", "text": "ftdna\n5\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 13, "cell_type": "code", "source": "for key in tokenizer.word_index.keys():\n    print key\n    print tokenizer.word_index[key]\n    break", "outputs": [{"output_type": "stream", "name": "stdout", "text": "ftdna\n197942\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 14, "cell_type": "code", "source": "for key in tokenizer.word_docs.keys():\n    print key\n    print tokenizer.word_docs[key]\n    break", "outputs": [{"output_type": "stream", "name": "stdout", "text": "ftdna\n5\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 15, "cell_type": "code", "source": "sampling_table = sequence.make_sampling_table(max_features)\n\nfor i, seq in enumerate(tokenizer.texts_to_sequences_generator(text_generator())):\n    print i\n    print seq\n    print \n    couples, labels = sequence.skipgrams(seq, max_features, window_size=4, negative_samples=1., sampling_table=sampling_table)\n    print couples\n    print labels\n    break", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0\n0\n[67, 11, 44, 20, 2, 2087, 13, 3, 943, 11399, 2, 587, 1, 140, 11597, 46, 1, 81, 831, 56, 2, 880, 12, 10814, 1197, 22, 11, 91, 2, 277, 53, 9, 839, 55, 61, 5, 41, 10]\n\n[[10814, 9256], [11399, 2], [11399, 13003], [10814, 91], [10814, 880], [943, 1], [91, 48182], [11399, 943], [11399, 13], [943, 4838], [91, 35764], [11399, 2087], [10814, 37241], [11597, 46], [91, 45176], [91, 10814], [943, 49865], [11399, 140], [91, 2], [91, 10042], [943, 13], [11399, 33764], [11597, 27125], [91, 4077], [943, 2], [943, 26688], [11399, 1], [11597, 1], [10814, 28034], [91, 53], [10814, 56], [10814, 22], [10814, 40207], [10814, 12], [10814, 31487], [11597, 20483], [11597, 587], [11399, 587], [11399, 44736], [11597, 1], [943, 2], [11597, 29849], [91, 48270], [11597, 25261], [10814, 11], [91, 44786], [943, 11756], [943, 3], [11399, 36687], [11597, 35004], [91, 1197], [943, 11399], [943, 587], [11597, 6931], [943, 28406], [10814, 45564], [10814, 118], [11399, 13712], [91, 277], [11399, 39915], [943, 29603], [91, 22], [943, 2087], [943, 21037], [91, 11], [91, 1821], [11399, 3], [11597, 41391], [11399, 43550], [11597, 140], [10814, 1197], [91, 9], [10814, 18400], [11597, 19987], [11597, 2], [11597, 81], [943, 48595], [11399, 34314], [11597, 831], [10814, 2]]\n[0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 17, "cell_type": "code", "source": "# training process\nif train_model:\n    if load_model:\n        print('Load model...')\n        model = six.moves.cPickle.load(open(os.path.join(save_dir, model_load_fname), 'rb'))\n    else:\n        print('Build model...')\n        model = Sequential()\n        model.add(WordContextProduct(max_features, proj_dim=dim_proj, init=\"uniform\"))\n        model.compile(loss='mse', optimizer='rmsprop')\n\n    sampling_table = sequence.make_sampling_table(max_features)\n\n    for e in range(nb_epoch):\n        print('-'*40)\n        print('Epoch', e)\n        print('-'*40)\n\n        progbar = generic_utils.Progbar(tokenizer.document_count)\n        samples_seen = 0\n        losses = []\n        \n        for i, seq in enumerate(tokenizer.texts_to_sequences_generator(text_generator())):\n            # get skipgram couples for one text in the dataset\n            couples, labels = sequence.skipgrams(seq, max_features, window_size=4, negative_samples=1., sampling_table=sampling_table)\n            if couples:\n                # one gradient update per sentence (one sentence = a few 1000s of word couples)\n                X = np.array(couples, dtype=\"int32\")\n                loss = model.train(X, labels)\n                losses.append(loss)\n                if len(losses) % 100 == 0:\n                    progbar.update(i, values=[(\"loss\", np.mean(losses))])\n                    losses = []\n                samples_seen += len(labels)\n        print('Samples seen:', samples_seen)\n    print(\"Training completed!\")\n\n    if save:\n        print(\"Saving model...\")\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        six.moves.cPickle.dump(model, open(os.path.join(save_dir, model_save_fname), \"wb\"))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Build model...\n----------------------------------------\n('Epoch', 0)\n----------------------------------------\n0\n   9955/5845908 [..............................] - ETA: 86679s - loss: 0.249910000\n  19969/5845908 [..............................] - ETA: 86977s - loss: 0.249520000\n  29957/5845908 [..............................] - ETA: 87000s - loss: 0.247530000\n  39894/5845908 [..............................] - ETA: 86817s - loss: 0.243540000\n  49917/5845908 [..............................] - ETA: 86646s - loss: 0.238650000\n  59958/5845908 [..............................] - ETA: 86460s - loss: 0.233560000\n  69969/5845908 [..............................] - ETA: 86289s - loss: 0.228870000\n  79918/5845908 [..............................] - ETA: 86136s - loss: 0.224480000\n  89986/5845908 [..............................] - ETA: 85902s - loss: 0.220390000\n  99908/5845908 [..............................] - ETA: 85736s - loss: 0.2165100000\n 109939/5845908 [..............................] - ETA: 85614s - loss: 0.2132110000\n 119950/5845908 [..............................] - ETA: 85540s - loss: 0.2100120000\n 129971/5845908 [..............................] - ETA: 85385s - loss: 0.2071130000\n 139944/5845908 [..............................] - ETA: 85201s - loss: 0.2043140000\n 149999/5845908 [..............................] - ETA: 85025s - loss: 0.2017150000\n 159922/5845908 [..............................] - ETA: 84869s - loss: 0.1993160000\n 169940/5845908 [..............................] - ETA: 84751s - loss: 0.1970170000\n 179957/5845908 [..............................] - ETA: 84596s - loss: 0.1948180000\n 189986/5845908 [..............................] - ETA: 84435s - loss: 0.1926190000\n 199916/5845908 [>.............................] - ETA: 84293s - loss: 0.1906200000\n 209956/5845908 [>.............................] - ETA: 84110s - loss: 0.1886210000\n 219927/5845908 [>.............................] - ETA: 83926s - loss: 0.1866220000\n 229971/5845908 [>.............................] - ETA: 83776s - loss: 0.1848230000\n 239972/5845908 [>.............................] - ETA: 83644s - loss: 0.1829240000\n 249930/5845908 [>.............................] - ETA: 83481s - loss: 0.1811250000\n 259946/5845908 [>.............................] - ETA: 83352s - loss: 0.1794260000\n 269962/5845908 [>.............................] - ETA: 83205s - loss: 0.1776270000\n 279927/5845908 [>.............................] - ETA: 83031s - loss: 0.1760280000\n 289985/5845908 [>.............................] - ETA: 82858s - loss: 0.1743290000\n 299907/5845908 [>.............................] - ETA: 82716s - loss: 0.1727300000\n 309999/5845908 [>.............................] - ETA: 82531s - loss: 0.1711310000\n 319993/5845908 [>.............................] - ETA: 82355s - loss: 0.1696320000\n 329940/5845908 [>.............................] - ETA: 82211s - loss: 0.1682330000\n 339985/5845908 [>.............................] - ETA: 82053s - loss: 0.1667340000\n 349973/5845908 [>.............................] - ETA: 81882s - loss: 0.1653350000\n 359985/5845908 [>.............................] - ETA: 81700s - loss: 0.1639360000\n 369966/5845908 [>.............................] - ETA: 81540s - loss: 0.1626370000\n 379954/5845908 [>.............................] - ETA: 81369s - loss: 0.1612380000\n 389982/5845908 [=>............................] - ETA: 81226s - loss: 0.1599390000\n 399935/5845908 [=>............................] - ETA: 81085s - loss: 0.1587400000\n 409942/5845908 [=>............................] - ETA: 80911s - loss: 0.1574410000\n 419984/5845908 [=>............................] - ETA: 80727s - loss: 0.1562420000\n 429940/5845908 [=>............................] - ETA: 80568s - loss: 0.1550430000\n 439948/5845908 [=>............................] - ETA: 80394s - loss: 0.1538440000\n 449954/5845908 [=>............................] - ETA: 80223s - loss: 0.1526450000\n 459944/5845908 [=>............................] - ETA: 80067s - loss: 0.1515460000\n 469950/5845908 [=>............................] - ETA: 79909s - loss: 0.1504470000\n 479944/5845908 [=>............................] - ETA: 79751s - loss: 0.1493480000\n 489945/5845908 [=>............................] - ETA: 79588s - loss: 0.1482490000\n 499928/5845908 [=>............................] - ETA: 79437s - loss: 0.1472500000\n 509937/5845908 [=>............................] - ETA: 79274s - loss: 0.1462510000\n 519894/5845908 [=>............................] - ETA: 79118s - loss: 0.1452520000\n 529940/5845908 [=>............................] - ETA: 78975s - loss: 0.1442530000\n 539931/5845908 [=>............................] - ETA: 78816s - loss: 0.1432540000\n 549905/5845908 [=>............................] - ETA: 78660s - loss: 0.1423550000\n 559965/5845908 [=>............................] - ETA: 78511s - loss: 0.1414560000\n 569975/5845908 [=>............................] - ETA: 78350s - loss: 0.1405570000\n 579954/5845908 [=>............................] - ETA: 78198s - loss: 0.1396580000\n 589898/5845908 [==>...........................] - ETA: 78052s - loss: 0.1388590000\n 599979/5845908 [==>...........................] - ETA: 77901s - loss: 0.1380600000\n 609925/5845908 [==>...........................] - ETA: 77752s - loss: 0.1372610000\n 619992/5845908 [==>...........................] - ETA: 77597s - loss: 0.1364620000\n 629927/5845908 [==>...........................] - ETA: 77454s - loss: 0.1356630000\n 639992/5845908 [==>...........................] - ETA: 77302s - loss: 0.1348640000\n 649910/5845908 [==>...........................] - ETA: 77162s - loss: 0.1341650000\n 659928/5845908 [==>...........................] - ETA: 77021s - loss: 0.1334660000\n 669957/5845908 [==>...........................] - ETA: 76885s - loss: 0.1327670000\n 679972/5845908 [==>...........................] - ETA: 76750s - loss: 0.1320680000\n 689950/5845908 [==>...........................] - ETA: 76603s - loss: 0.1313690000\n 699983/5845908 [==>...........................] - ETA: 76459s - loss: 0.1306700000\n 709966/5845908 [==>...........................] - ETA: 76309s - loss: 0.1300710000\n 719902/5845908 [==>...........................] - ETA: 76161s - loss: 0.1293720000\n 729916/5845908 [==>...........................] - ETA: 76018s - loss: 0.1287730000\n 739905/5845908 [==>...........................] - ETA: 75869s - loss: 0.1281740000\n 749983/5845908 [==>...........................] - ETA: 75713s - loss: 0.1275750000\n 759961/5845908 [==>...........................] - ETA: 75560s - loss: 0.1269760000\n 769909/5845908 [==>...........................] - ETA: 75417s - loss: 0.1263770000\n 779976/5845908 [===>..........................] - ETA: 75268s - loss: 0.1258780000\n 789990/5845908 [===>..........................] - ETA: 75111s - loss: 0.1252790000\n 799941/5845908 [===>..........................] - ETA: 74962s - loss: 0.1247800000\n 809932/5845908 [===>..........................] - ETA: 74814s - loss: 0.1241810000\n 819908/5845908 [===>..........................] - ETA: 74661s - loss: 0.1236820000\n 829953/5845908 [===>..........................] - ETA: 74510s - loss: 0.1230830000\n 839891/5845908 [===>..........................] - ETA: 74364s - loss: 0.1225840000\n 849907/5845908 [===>..........................] - ETA: 74201s - loss: 0.1220850000\n 859932/5845908 [===>..........................] - ETA: 74040s - loss: 0.1215860000\n 869945/5845908 [===>..........................] - ETA: 73885s - loss: 0.1210870000\n 879935/5845908 [===>..........................] - ETA: 73728s - loss: 0.1205880000\n 889941/5845908 [===>..........................] - ETA: 73573s - loss: 0.1200890000\n 899988/5845908 [===>..........................] - ETA: 73424s - loss: 0.1195900000\n 909965/5845908 [===>..........................] - ETA: 73273s - loss: 0.1191910000\n 919933/5845908 [===>..........................] - ETA: 73122s - loss: 0.1186920000\n 929971/5845908 [===>..........................] - ETA: 72962s - loss: 0.1181930000\n 939956/5845908 [===>..........................] - ETA: 72813s - loss: 0.1177940000\n 949958/5845908 [===>..........................] - ETA: 72662s - loss: 0.1173950000\n 959950/5845908 [===>..........................] - ETA: 72510s - loss: 0.1169960000\n 969997/5845908 [===>..........................] - ETA: 72363s - loss: 0.1165970000\n 979957/5845908 [====>.........................] - ETA: 72213s - loss: 0.1161980000\n 989921/5845908 [====>.........................] - ETA: 72064s - loss: 0.1157990000\n 999906/5845908 [====>.........................] - ETA: 71911s - loss: 0.11521000000\n1009944/5845908 [====>.........................] - ETA: 71757s - loss: 0.11491010000\n1019976/5845908 [====>.........................] - ETA: 71612s - loss: 0.11451020000\n1029970/5845908 [====>.........................] - ETA: 71462s - loss: 0.11411030000\n1039916/5845908 [====>.........................] - ETA: 71317s - loss: 0.11371040000\n1049989/5845908 [====>.........................] - ETA: 71165s - loss: 0.11341050000\n1059941/5845908 [====>.........................] - ETA: 71016s - loss: 0.11301060000\n1069939/5845908 [====>.........................] - ETA: 70876s - loss: 0.11261070000\n1079999/5845908 [====>.........................] - ETA: 70721s - loss: 0.11231080000\n1089949/5845908 [====>.........................] - ETA: 70578s - loss: 0.11191090000\n1099987/5845908 [====>.........................] - ETA: 70432s - loss: 0.11161100000\n1109915/5845908 [====>.........................] - ETA: 70286s - loss: 0.11131110000\n1119913/5845908 [====>.........................] - ETA: 70133s - loss: 0.11091120000\n1129953/5845908 [====>.........................] - ETA: 69987s - loss: 0.11061130000\n1139899/5845908 [====>.........................] - ETA: 69840s - loss: 0.11031140000\n1149963/5845908 [====>.........................] - ETA: 69690s - loss: 0.11001150000\n1159960/5845908 [====>.........................] - ETA: 69547s - loss: 0.10971160000\n1169936/5845908 [=====>........................] - ETA: 69399s - loss: 0.10941170000\n1179997/5845908 [=====>........................] - ETA: 69249s - loss: 0.10911180000\n1189939/5845908 [=====>........................] - ETA: 69102s - loss: 0.10881190000\n1199957/5845908 [=====>........................] - ETA: 68959s - loss: 0.10851200000\n1209988/5845908 [=====>........................] - ETA: 68812s - loss: 0.10821210000\n1219978/5845908 [=====>........................] - ETA: 68661s - loss: 0.10791220000\n1229972/5845908 [=====>........................] - ETA: 68522s - loss: 0.10761230000\n1239933/5845908 [=====>........................] - ETA: 68373s - loss: 0.10741240000\n1249960/5845908 [=====>........................] - ETA: 68227s - loss: 0.10711250000\n1259924/5845908 [=====>........................] - ETA: 68081s - loss: 0.10681260000\n1269944/5845908 [=====>........................] - ETA: 67935s - loss: 0.10661270000\n1279918/5845908 [=====>........................] - ETA: 67793s - loss: 0.10631280000\n1289951/5845908 [=====>........................] - ETA: 67648s - loss: 0.10601290000\n1299970/5845908 [=====>........................] - ETA: 67495s - loss: 0.10581300000\n1309947/5845908 [=====>........................] - ETA: 67345s - loss: 0.10551310000\n1319979/5845908 [=====>........................] - ETA: 67198s - loss: 0.10531320000\n1329949/5845908 [=====>........................] - ETA: 67048s - loss: 0.10501330000\n1339972/5845908 [=====>........................] - ETA: 66901s - loss: 0.10481340000\n1349909/5845908 [=====>........................] - ETA: 66754s - loss: 0.10451350000\n1359963/5845908 [=====>........................] - ETA: 66604s - loss: 0.10431360000\n1369991/5845908 [======>.......................] - ETA: 66459s - loss: 0.10411370000\n1379922/5845908 [======>.......................] - ETA: 66315s - loss: 0.10381380000\n1389902/5845908 [======>.......................] - ETA: 66165s - loss: 0.10361390000\n1399965/5845908 [======>.......................] - ETA: 66015s - loss: 0.10341400000\n1409916/5845908 [======>.......................] - ETA: 65867s - loss: 0.10321410000\n1419967/5845908 [======>.......................] - ETA: 65718s - loss: 0.10291420000\n1429914/5845908 [======>.......................] - ETA: 65569s - loss: 0.10271430000\n1439972/5845908 [======>.......................] - ETA: 65419s - loss: 0.10251440000\n1449957/5845908 [======>.......................] - ETA: 65269s - loss: 0.10231450000\n1459988/5845908 [======>.......................] - ETA: 65122s - loss: 0.10211460000\n1469916/5845908 [======>.......................] - ETA: 64977s - loss: 0.10191470000\n1479940/5845908 [======>.......................] - ETA: 64832s - loss: 0.10171480000\n1489900/5845908 [======>.......................] - ETA: 64684s - loss: 0.10151490000\n1499963/5845908 [======>.......................] - ETA: 64534s - loss: 0.10131500000\n1509907/5845908 [======>.......................] - ETA: 64391s - loss: 0.10111510000\n1519903/5845908 [======>.......................] - ETA: 64240s - loss: 0.10091520000\n1529995/5845908 [======>.......................] - ETA: 64088s - loss: 0.10071530000\n1539949/5845908 [======>.......................] - ETA: 63941s - loss: 0.10051540000\n1549941/5845908 [======>.......................] - ETA: 63790s - loss: 0.10031550000\n1559965/5845908 [=======>......................] - ETA: 63641s - loss: 0.10011560000\n1569922/5845908 [=======>......................] - ETA: 63494s - loss: 0.09991570000\n1579975/5845908 [=======>......................] - ETA: 63344s - loss: 0.09971580000\n1589997/5845908 [=======>......................] - ETA: 63191s - loss: 0.09951590000\n1599995/5845908 [=======>......................] - ETA: 63039s - loss: 0.09931600000\n1609967/5845908 [=======>......................] - ETA: 62891s - loss: 0.09911610000\n1619931/5845908 [=======>......................] - ETA: 62741s - loss: 0.09901620000\n1629982/5845908 [=======>......................] - ETA: 62593s - loss: 0.09881630000\n1639899/5845908 [=======>......................] - ETA: 62450s - loss: 0.09861640000\n1649896/5845908 [=======>......................] - ETA: 62300s - loss: 0.09841650000\n1659949/5845908 [=======>......................] - ETA: 62151s - loss: 0.09831660000\n1669998/5845908 [=======>......................] - ETA: 62003s - loss: 0.09811670000\n1679998/5845908 [=======>......................] - ETA: 61851s - loss: 0.09791680000\n1689961/5845908 [=======>......................] - ETA: 61702s - loss: 0.09781690000\n1699939/5845908 [=======>......................] - ETA: 61552s - loss: 0.09761700000\n1709949/5845908 [=======>......................] - ETA: 61400s - loss: 0.09741710000\n1719998/5845908 [=======>......................] - ETA: 61251s - loss: 0.09721720000\n1729938/5845908 [=======>......................] - ETA: 61104s - loss: 0.09711730000\n1739949/5845908 [=======>......................] - ETA: 60953s - loss: 0.09691740000\n1749963/5845908 [=======>......................] - ETA: 60802s - loss: 0.09681750000\n1759967/5845908 [========>.....................] - ETA: 60652s - loss: 0.09661760000\n1769979/5845908 [========>.....................] - ETA: 60502s - loss: 0.09651770000\n1779933/5845908 [========>.....................] - ETA: 60354s - loss: 0.09631780000\n1789986/5845908 [========>.....................] - ETA: 60206s - loss: 0.09621790000\n1799917/5845908 [========>.....................] - ETA: 60059s - loss: 0.09601800000\n1809925/5845908 [========>.....................] - ETA: 59908s - loss: 0.09591810000\n1819937/5845908 [========>.....................] - ETA: 59759s - loss: 0.09571820000\n1829913/5845908 [========>.....................] - ETA: 59605s - loss: 0.09561830000\n1839963/5845908 [========>.....................] - ETA: 59457s - loss: 0.09541840000\n1849948/5845908 [========>.....................] - ETA: 59308s - loss: 0.09531850000\n1859950/5845908 [========>.....................] - ETA: 59157s - loss: 0.09511860000\n1869918/5845908 [========>.....................] - ETA: 59009s - loss: 0.09501870000\n1879963/5845908 [========>.....................] - ETA: 58859s - loss: 0.09481880000\n1889909/5845908 [========>.....................] - ETA: 58712s - loss: 0.09471890000\n1899978/5845908 [========>.....................] - ETA: 58563s - loss: 0.09461900000\n1909968/5845908 [========>.....................] - ETA: 58414s - loss: 0.09441910000\n1919899/5845908 [========>.....................] - ETA: 58268s - loss: 0.09431920000\n1929965/5845908 [========>.....................] - ETA: 58118s - loss: 0.09411930000\n1939925/5845908 [========>.....................] - ETA: 57972s - loss: 0.09401940000\n1949965/5845908 [=========>....................] - ETA: 57823s - loss: 0.09391950000\n1959965/5845908 [=========>....................] - ETA: 57673s - loss: 0.09371960000\n1969968/5845908 [=========>....................] - ETA: 57523s - loss: 0.09361970000\n1979972/5845908 [=========>....................] - ETA: 57373s - loss: 0.09351980000\n1989997/5845908 [=========>....................] - ETA: 57220s - loss: 0.09331990000\n1999944/5845908 [=========>....................] - ETA: 57073s - loss: 0.09322000000\n2009921/5845908 [=========>....................] - ETA: 56924s - loss: 0.09312010000\n2019922/5845908 [=========>....................] - ETA: 56773s - loss: 0.09292020000\n2029973/5845908 [=========>....................] - ETA: 56625s - loss: 0.09282030000\n2039939/5845908 [=========>....................] - ETA: 56479s - loss: 0.09272040000\n2049919/5845908 [=========>....................] - ETA: 56331s - loss: 0.09262050000\n2059964/5845908 [=========>....................] - ETA: 56182s - loss: 0.09242060000\n2069902/5845908 [=========>....................] - ETA: 56035s - loss: 0.09232070000\n2079941/5845908 [=========>....................] - ETA: 55886s - loss: 0.09222080000\n2089994/5845908 [=========>....................] - ETA: 55736s - loss: 0.09212090000\n2099991/5845908 [=========>....................] - ETA: 55586s - loss: 0.09202100000\n2109948/5845908 [=========>....................] - ETA: 55439s - loss: 0.09192110000\n2119987/5845908 [=========>....................] - ETA: 55292s - loss: 0.09172120000\n2129961/5845908 [=========>....................] - ETA: 55145s - loss: 0.09162130000\n2139946/5845908 [=========>....................] - ETA: 54995s - loss: 0.09152140000\n2149995/5845908 [==========>...................] - ETA: 54845s - loss: 0.09142150000\n2159952/5845908 [==========>...................] - ETA: 54699s - loss: 0.09132160000\n2169928/5845908 [==========>...................] - ETA: 54551s - loss: 0.09122170000\n2179896/5845908 [==========>...................] - ETA: 54402s - loss: 0.09112180000\n2189963/5845908 [==========>...................] - ETA: 54253s - loss: 0.09102190000\n2199921/5845908 [==========>...................] - ETA: 54105s - loss: 0.09092200000\n2209974/5845908 [==========>...................] - ETA: 53957s - loss: 0.09082210000\n2219924/5845908 [==========>...................] - ETA: 53810s - loss: 0.09072220000\n2229905/5845908 [==========>...................] - ETA: 53661s - loss: 0.09062230000\n2239957/5845908 [==========>...................] - ETA: 53513s - loss: 0.09052240000\n2249900/5845908 [==========>...................] - ETA: 53366s - loss: 0.09042250000\n2259983/5845908 [==========>...................] - ETA: 53216s - loss: 0.09022260000\n2269954/5845908 [==========>...................] - ETA: 53068s - loss: 0.09012270000\n2279949/5845908 [==========>...................] - ETA: 52918s - loss: 0.09002280000\n2289996/5845908 [==========>...................] - ETA: 52770s - loss: 0.08992290000\n2299975/5845908 [==========>...................] - ETA: 52623s - loss: 0.08982300000\n2309950/5845908 [==========>...................] - ETA: 52475s - loss: 0.08972310000\n2319930/5845908 [==========>...................] - ETA: 52327s - loss: 0.08962320000\n2329983/5845908 [==========>...................] - ETA: 52178s - loss: 0.08962330000\n2339997/5845908 [===========>..................] - ETA: 52031s - loss: 0.08952340000\n2349978/5845908 [===========>..................] - ETA: 51882s - loss: 0.08942350000\n2359984/5845908 [===========>..................] - ETA: 51732s - loss: 0.08932360000\n2369974/5845908 [===========>..................] - ETA: 51584s - loss: 0.08922370000\n2379985/5845908 [===========>..................] - ETA: 51433s - loss: 0.08912380000\n2389955/5845908 [===========>..................] - ETA: 51284s - loss: 0.08902390000\n2399922/5845908 [===========>..................] - ETA: 51137s - loss: 0.08892400000\n2409925/5845908 [===========>..................] - ETA: 50987s - loss: 0.08882410000\n2419977/5845908 [===========>..................] - ETA: 50838s - loss: 0.08872420000\n2429952/5845908 [===========>..................] - ETA: 50689s - loss: 0.08862430000\n2439969/5845908 [===========>..................] - ETA: 50542s - loss: 0.08852440000\n2449955/5845908 [===========>..................] - ETA: 50392s - loss: 0.08842450000\n2459945/5845908 [===========>..................] - ETA: 50242s - loss: 0.08832460000\n2469927/5845908 [===========>..................] - ETA: 50093s - loss: 0.08822470000\n2479896/5845908 [===========>..................] - ETA: 49944s - loss: 0.08822480000\n2489968/5845908 [===========>..................] - ETA: 49795s - loss: 0.08812490000\n2499952/5845908 [===========>..................] - ETA: 49647s - loss: 0.08802500000\n2509919/5845908 [===========>..................] - ETA: 49498s - loss: 0.08792510000\n2519944/5845908 [===========>..................] - ETA: 49350s - loss: 0.08782520000\n2529912/5845908 [===========>..................] - ETA: 49201s - loss: 0.08772530000\n2539983/5845908 [============>.................] - ETA: 49050s - loss: 0.08762540000\n2549939/5845908 [============>.................] - ETA: 48902s - loss: 0.08752550000\n2559916/5845908 [============>.................] - ETA: 48753s - loss: 0.08752560000\n2569930/5845908 [============>.................] - ETA: 48603s - loss: 0.08742570000\n2579994/5845908 [============>.................] - ETA: 48453s - loss: 0.08732580000\n2589933/5845908 [============>.................] - ETA: 48305s - loss: 0.08722590000\n2599953/5845908 [============>.................] - ETA: 48157s - loss: 0.08712600000\n2609899/5845908 [============>.................] - ETA: 48010s - loss: 0.08702610000\n2619999/5845908 [============>.................] - ETA: 47859s - loss: 0.08702620000\n2629939/5845908 [============>.................] - ETA: 47711s - loss: 0.08692630000\n2639925/5845908 [============>.................] - ETA: 47562s - loss: 0.08682640000\n2649901/5845908 [============>.................] - ETA: 47413s - loss: 0.08672650000\n2659952/5845908 [============>.................] - ETA: 47264s - loss: 0.08662660000\n2669983/5845908 [============>.................] - ETA: 47115s - loss: 0.08652670000\n2679938/5845908 [============>.................] - ETA: 46967s - loss: 0.08652680000\n2689974/5845908 [============>.................] - ETA: 46820s - loss: 0.08642690000\n2699949/5845908 [============>.................] - ETA: 46672s - loss: 0.08632700000\n2709929/5845908 [============>.................] - ETA: 46525s - loss: 0.08622710000\n2719999/5845908 [============>.................] - ETA: 46376s - loss: 0.08622720000\n2729944/5845908 [=============>................] - ETA: 46230s - loss: 0.08612730000\n2739905/5845908 [=============>................] - ETA: 46083s - loss: 0.08602740000\n2749967/5845908 [=============>................] - ETA: 45934s - loss: 0.08592750000\n2759936/5845908 [=============>................] - ETA: 45787s - loss: 0.08592760000\n2769994/5845908 [=============>................] - ETA: 45638s - loss: 0.08582770000\n2779970/5845908 [=============>................] - ETA: 45489s - loss: 0.08572780000\n2789902/5845908 [=============>................] - ETA: 45343s - loss: 0.08562790000\n2799919/5845908 [=============>................] - ETA: 45194s - loss: 0.08562800000\n2809950/5845908 [=============>................] - ETA: 45046s - loss: 0.08552810000\n2819927/5845908 [=============>................] - ETA: 44899s - loss: 0.08542820000\n2829932/5845908 [=============>................] - ETA: 44750s - loss: 0.08542830000\n2839994/5845908 [=============>................] - ETA: 44601s - loss: 0.08532840000\n2849965/5845908 [=============>................] - ETA: 44452s - loss: 0.08522850000\n2859957/5845908 [=============>................] - ETA: 44306s - loss: 0.08512860000\n2869947/5845908 [=============>................] - ETA: 44157s - loss: 0.08512870000\n2879974/5845908 [=============>................] - ETA: 44009s - loss: 0.08502880000\n2889973/5845908 [=============>................] - ETA: 43860s - loss: 0.08492890000\n2899904/5845908 [=============>................] - ETA: 43713s - loss: 0.08492900000\n2909954/5845908 [=============>................] - ETA: 43565s - loss: 0.08482910000\n2919921/5845908 [=============>................] - ETA: 43417s - loss: 0.08472920000\n2929977/5845908 [==============>...............] - ETA: 43268s - loss: 0.08472930000\n2939965/5845908 [==============>...............] - ETA: 43119s - loss: 0.08462940000\n2949997/5845908 [==============>...............] - ETA: 42970s - loss: 0.08452950000\n2959944/5845908 [==============>...............] - ETA: 42823s - loss: 0.08442960000\n2969930/5845908 [==============>...............] - ETA: 42676s - loss: 0.08442970000\n2979995/5845908 [==============>...............] - ETA: 42526s - loss: 0.08432980000\n2989976/5845908 [==============>...............] - ETA: 42379s - loss: 0.08432990000\n2999932/5845908 [==============>...............] - ETA: 42232s - loss: 0.08423000000\n3009907/5845908 [==============>...............] - ETA: 42083s - loss: 0.08413010000\n3019953/5845908 [==============>...............] - ETA: 41934s - loss: 0.08413020000\n3029942/5845908 [==============>...............] - ETA: 41786s - loss: 0.08403030000\n3039986/5845908 [==============>...............] - ETA: 41637s - loss: 0.08393040000\n3049935/5845908 [==============>...............] - ETA: 41489s - loss: 0.08393050000\n3059996/5845908 [==============>...............] - ETA: 41339s - loss: 0.08383060000\n3069971/5845908 [==============>...............] - ETA: 41190s - loss: 0.08383070000\n3079954/5845908 [==============>...............] - ETA: 41042s - loss: 0.08373080000\n3089998/5845908 [==============>...............] - ETA: 40893s - loss: 0.08363090000\n3099952/5845908 [==============>...............] - ETA: 40746s - loss: 0.08363100000\n3109986/5845908 [==============>...............] - ETA: 40597s - loss: 0.08353110000\n3119919/5845908 [===============>..............] - ETA: 40450s - loss: 0.08343120000\n3129969/5845908 [===============>..............] - ETA: 40300s - loss: 0.08343130000\n3139947/5845908 [===============>..............] - ETA: 40152s - loss: 0.08333140000\n3149954/5845908 [===============>..............] - ETA: 40003s - loss: 0.08333150000\n3159897/5845908 [===============>..............] - ETA: 39855s - loss: 0.08323160000\n3169988/5845908 [===============>..............] - ETA: 39705s - loss: 0.08313170000\n3179960/5845908 [===============>..............] - ETA: 39557s - loss: 0.08313180000\n3189946/5845908 [===============>..............] - ETA: 39408s - loss: 0.08303190000\n3199918/5845908 [===============>..............] - ETA: 39259s - loss: 0.08293200000\n3209979/5845908 [===============>..............] - ETA: 39110s - loss: 0.08293210000\n3219917/5845908 [===============>..............] - ETA: 38963s - loss: 0.08283220000\n3229993/5845908 [===============>..............] - ETA: 38813s - loss: 0.08283230000\n3239944/5845908 [===============>..............] - ETA: 38665s - loss: 0.08273240000\n3249924/5845908 [===============>..............] - ETA: 38517s - loss: 0.08273250000\n3259927/5845908 [===============>..............] - ETA: 38368s - loss: 0.08263260000\n3269942/5845908 [===============>..............] - ETA: 38220s - loss: 0.08253270000\n3279974/5845908 [===============>..............] - ETA: 38073s - loss: 0.08253280000\n3289977/5845908 [===============>..............] - ETA: 37925s - loss: 0.08243290000\n3299991/5845908 [===============>..............] - ETA: 37779s - loss: 0.08243300000\n3309933/5845908 [===============>..............] - ETA: 37632s - loss: 0.08233310000\n3319970/5845908 [================>.............] - ETA: 37483s - loss: 0.08233320000\n3329993/5845908 [================>.............] - ETA: 37335s - loss: 0.08223330000\n3339968/5845908 [================>.............] - ETA: 37189s - loss: 0.08223340000\n3349923/5845908 [================>.............] - ETA: 37042s - loss: 0.08213350000\n3359983/5845908 [================>.............] - ETA: 36893s - loss: 0.08213360000\n3369991/5845908 [================>.............] - ETA: 36745s - loss: 0.08203370000\n3379909/5845908 [================>.............] - ETA: 36599s - loss: 0.08203380000\n3389916/5845908 [================>.............] - ETA: 36451s - loss: 0.08193390000\n3399933/5845908 [================>.............] - ETA: 36303s - loss: 0.08193400000\n3409898/5845908 [================>.............] - ETA: 36155s - loss: 0.08183410000\n3419924/5845908 [================>.............] - ETA: 36007s - loss: 0.08173420000\n3429955/5845908 [================>.............] - ETA: 35859s - loss: 0.08173430000\n3439946/5845908 [================>.............] - ETA: 35711s - loss: 0.08163440000\n3449919/5845908 [================>.............] - ETA: 35565s - loss: 0.08163450000\n3459970/5845908 [================>.............] - ETA: 35416s - loss: 0.08153460000\n3469971/5845908 [================>.............] - ETA: 35268s - loss: 0.08153470000\n3479963/5845908 [================>.............] - ETA: 35122s - loss: 0.08143480000\n3489962/5845908 [================>.............] - ETA: 34975s - loss: 0.08143490000\n3499911/5845908 [================>.............] - ETA: 34828s - loss: 0.08133500000\n3509935/5845908 [=================>............] - ETA: 34681s - loss: 0.08133510000\n3519993/5845908 [=================>............] - ETA: 34533s - loss: 0.08133520000\n3529933/5845908 [=================>............] - ETA: 34387s - loss: 0.08123530000\n3539955/5845908 [=================>............] - ETA: 34239s - loss: 0.08123540000\n3549964/5845908 [=================>............] - ETA: 34092s - loss: 0.08113550000\n3559961/5845908 [=================>............] - ETA: 33944s - loss: 0.08113560000\n3569994/5845908 [=================>............] - ETA: 33795s - loss: 0.08103570000\n3579928/5845908 [=================>............] - ETA: 33648s - loss: 0.08103580000\n3589899/5845908 [=================>............] - ETA: 33500s - loss: 0.08093590000\n3599921/5845908 [=================>............] - ETA: 33352s - loss: 0.08093600000\n3609965/5845908 [=================>............] - ETA: 33204s - loss: 0.08083610000\n3619934/5845908 [=================>............] - ETA: 33056s - loss: 0.08083620000\n3629966/5845908 [=================>............] - ETA: 32908s - loss: 0.08073630000\n3639992/5845908 [=================>............] - ETA: 32759s - loss: 0.08073640000\n3649927/5845908 [=================>............] - ETA: 32612s - loss: 0.08073650000\n3659979/5845908 [=================>............] - ETA: 32463s - loss: 0.08063660000\n3669961/5845908 [=================>............] - ETA: 32314s - loss: 0.08063670000\n3679995/5845908 [=================>............] - ETA: 32166s - loss: 0.08053680000\n3689934/5845908 [=================>............] - ETA: 32019s - loss: 0.08053690000\n3699980/5845908 [=================>............] - ETA: 31870s - loss: 0.08043700000\n3709998/5845908 [==================>...........] - ETA: 31722s - loss: 0.08043710000\n3719936/5845908 [==================>...........] - ETA: 31576s - loss: 0.08033720000\n3729904/5845908 [==================>...........] - ETA: 31428s - loss: 0.08033730000\n3739972/5845908 [==================>...........] - ETA: 31278s - loss: 0.08023740000\n3749947/5845908 [==================>...........] - ETA: 31130s - loss: 0.08023750000\n3759974/5845908 [==================>...........] - ETA: 30981s - loss: 0.08023760000\n3769917/5845908 [==================>...........] - ETA: 30833s - loss: 0.08013770000\n3779996/5845908 [==================>...........] - ETA: 30682s - loss: 0.08013780000\n3789906/5845908 [==================>...........] - ETA: 30536s - loss: 0.08003790000\n3799918/5845908 [==================>...........] - ETA: 30386s - loss: 0.08003800000\n3809937/5845908 [==================>...........] - ETA: 30237s - loss: 0.07993810000\n3819984/5845908 [==================>...........] - ETA: 30088s - loss: 0.07993820000\n3829924/5845908 [==================>...........] - ETA: 29940s - loss: 0.07983830000\n3839973/5845908 [==================>...........] - ETA: 29791s - loss: 0.07983840000\n3849914/5845908 [==================>...........] - ETA: 29643s - loss: 0.07983850000\n3859988/5845908 [==================>...........] - ETA: 29493s - loss: 0.07973860000\n3869937/5845908 [==================>...........] - ETA: 29345s - loss: 0.07973870000\n3879901/5845908 [==================>...........] - ETA: 29196s - loss: 0.07963880000\n3889905/5845908 [==================>...........] - ETA: 29048s - loss: 0.07963890000\n3899971/5845908 [===================>..........] - ETA: 28898s - loss: 0.07953900000\n3909903/5845908 [===================>..........] - ETA: 28751s - loss: 0.07953910000\n3919966/5845908 [===================>..........] - ETA: 28601s - loss: 0.07953920000\n3929976/5845908 [===================>..........] - ETA: 28454s - loss: 0.07943930000\n3939909/5845908 [===================>..........] - ETA: 28306s - loss: 0.07943940000\n3949952/5845908 [===================>..........] - ETA: 28157s - loss: 0.07933950000\n3959937/5845908 [===================>..........] - ETA: 28007s - loss: 0.07933960000\n3969940/5845908 [===================>..........] - ETA: 27860s - loss: 0.07933970000\n3979973/5845908 [===================>..........] - ETA: 27710s - loss: 0.07923980000\n3989987/5845908 [===================>..........] - ETA: 27560s - loss: 0.07923990000\n3999904/5845908 [===================>..........] - ETA: 27412s - loss: 0.07914000000\n4009968/5845908 [===================>..........] - ETA: 27261s - loss: 0.07914010000\n4019917/5845908 [===================>..........] - ETA: 27112s - loss: 0.07914020000\n4029953/5845908 [===================>..........] - ETA: 26963s - loss: 0.07904030000\n4039999/5845908 [===================>..........] - ETA: 26814s - loss: 0.07904040000\n4049972/5845908 [===================>..........] - ETA: 26665s - loss: 0.07894050000\n4059941/5845908 [===================>..........] - ETA: 26517s - loss: 0.07894060000\n4069931/5845908 [===================>..........] - ETA: 26368s - loss: 0.07894070000\n4079966/5845908 [===================>..........] - ETA: 26279s - loss: 0.07884080000\n4089924/5845908 [===================>..........] - ETA: 26131s - loss: 0.07884090000\n4099979/5845908 [====================>.........] - ETA: 25981s - loss: 0.07884100000\n4109920/5845908 [====================>.........] - ETA: 25833s - loss: 0.07874110000\n4119995/5845908 [====================>.........] - ETA: 25683s - loss: 0.07874120000\n4129991/5845908 [====================>.........] - ETA: 25534s - loss: 0.07864130000\n4139900/5845908 [====================>.........] - ETA: 25386s - loss: 0.07864140000\n4149998/5845908 [====================>.........] - ETA: 25235s - loss: 0.07864150000\n4159922/5845908 [====================>.........] - ETA: 25087s - loss: 0.07854160000\n4169952/5845908 [====================>.........] - ETA: 24938s - loss: 0.07854170000\n4179995/5845908 [====================>.........] - ETA: 24789s - loss: 0.07854180000\n4189973/5845908 [====================>.........] - ETA: 24640s - loss: 0.07844190000\n4199942/5845908 [====================>.........] - ETA: 24491s - loss: 0.07844200000\n4209912/5845908 [====================>.........] - ETA: 24343s - loss: 0.07844210000\n4219927/5845908 [====================>.........] - ETA: 24194s - loss: 0.07834220000\n4229996/5845908 [====================>.........] - ETA: 24044s - loss: 0.07834230000\n4239971/5845908 [====================>.........] - ETA: 23895s - loss: 0.07824240000\n4249985/5845908 [====================>.........] - ETA: 23747s - loss: 0.07824250000\n4259978/5845908 [====================>.........] - ETA: 23597s - loss: 0.07824260000\n4269965/5845908 [====================>.........] - ETA: 23448s - loss: 0.07814270000\n4279933/5845908 [====================>.........] - ETA: 23299s - loss: 0.07814280000\n4289926/5845908 [=====================>........] - ETA: 23150s - loss: 0.07814290000\n4299923/5845908 [=====================>........] - ETA: 23001s - loss: 0.07804300000\n4309958/5845908 [=====================>........] - ETA: 22852s - loss: 0.07804310000\n4319951/5845908 [=====================>........] - ETA: 22703s - loss: 0.07804320000\n4329965/5845908 [=====================>........] - ETA: 22553s - loss: 0.07794330000\n4339970/5845908 [=====================>........] - ETA: 22404s - loss: 0.07794340000\n4349989/5845908 [=====================>........] - ETA: 22254s - loss: 0.07794350000\n4359948/5845908 [=====================>........] - ETA: 22106s - loss: 0.07784360000\n4369936/5845908 [=====================>........] - ETA: 21957s - loss: 0.07784370000\n4379985/5845908 [=====================>........] - ETA: 21807s - loss: 0.07784380000\n4389951/5845908 [=====================>........] - ETA: 21659s - loss: 0.07774390000\n4399901/5845908 [=====================>........] - ETA: 21511s - loss: 0.07774400000\n4409960/5845908 [=====================>........] - ETA: 21361s - loss: 0.07774410000\n4419904/5845908 [=====================>........] - ETA: 21213s - loss: 0.07764420000\n4429996/5845908 [=====================>........] - ETA: 21062s - loss: 0.07764430000\n4439954/5845908 [=====================>........] - ETA: 20914s - loss: 0.07764440000\n4449924/5845908 [=====================>........] - ETA: 20765s - loss: 0.07754450000\n4459983/5845908 [=====================>........] - ETA: 20615s - loss: 0.07754460000\n4469928/5845908 [=====================>........] - ETA: 20467s - loss: 0.07754470000\n4479909/5845908 [=====================>........] - ETA: 20319s - loss: 0.07744480000\n4489958/5845908 [======================>.......] - ETA: 20169s - loss: 0.07744490000\n4499995/5845908 [======================>.......] - ETA: 20020s - loss: 0.07744500000\n4509938/5845908 [======================>.......] - ETA: 19872s - loss: 0.07734510000\n4519919/5845908 [======================>.......] - ETA: 19723s - loss: 0.07734520000\n4529951/5845908 [======================>.......] - ETA: 19574s - loss: 0.07734530000\n4539929/5845908 [======================>.......] - ETA: 19426s - loss: 0.07734540000\n4549992/5845908 [======================>.......] - ETA: 19276s - loss: 0.07724550000\n4559980/5845908 [======================>.......] - ETA: 19127s - loss: 0.07724560000\n4569923/5845908 [======================>.......] - ETA: 18979s - loss: 0.07724570000\n4579900/5845908 [======================>.......] - ETA: 18830s - loss: 0.07714580000\n4589981/5845908 [======================>.......] - ETA: 18680s - loss: 0.07714590000\n4599972/5845908 [======================>.......] - ETA: 18531s - loss: 0.07714600000\n4609931/5845908 [======================>.......] - ETA: 18383s - loss: 0.07704610000\n4619901/5845908 [======================>.......] - ETA: 18234s - loss: 0.07704620000\n4629963/5845908 [======================>.......] - ETA: 18085s - loss: 0.07704630000\n4639909/5845908 [======================>.......] - ETA: 17937s - loss: 0.07704640000\n4649939/5845908 [======================>.......] - ETA: 17787s - loss: 0.07694650000\n4659972/5845908 [======================>.......] - ETA: 17638s - loss: 0.07694660000\n4669946/5845908 [======================>.......] - ETA: 17491s - loss: 0.07694670000\n4679973/5845908 [=======================>......] - ETA: 17345s - loss: 0.07684680000\n4689957/5845908 [=======================>......] - ETA: 17198s - loss: 0.07684690000\n4699987/5845908 [=======================>......] - ETA: 17051s - loss: 0.07684700000\n4709965/5845908 [=======================>......] - ETA: 16905s - loss: 0.07684710000\n4719996/5845908 [=======================>......] - ETA: 16758s - loss: 0.07674720000\n4729907/5845908 [=======================>......] - ETA: 16610s - loss: 0.07674730000\n4739960/5845908 [=======================>......] - ETA: 16461s - loss: 0.07674740000\n4749943/5845908 [=======================>......] - ETA: 16312s - loss: 0.07664750000\n4759949/5845908 [=======================>......] - ETA: 16165s - loss: 0.07664760000\n4769899/5845908 [=======================>......] - ETA: 16019s - loss: 0.07664770000\n4779996/5845908 [=======================>......] - ETA: 15871s - loss: 0.07654780000\n4789965/5845908 [=======================>......] - ETA: 15724s - loss: 0.07654790000\n4799993/5845908 [=======================>......] - ETA: 15577s - loss: 0.07654800000\n4809937/5845908 [=======================>......] - ETA: 15429s - loss: 0.07654810000\n4819963/5845908 [=======================>......] - ETA: 15280s - loss: 0.07644820000\n4829922/5845908 [=======================>......] - ETA: 15131s - loss: 0.07644830000\n4839967/5845908 [=======================>......] - ETA: 14982s - loss: 0.07644840000\n4849932/5845908 [=======================>......] - ETA: 14833s - loss: 0.07634850000\n4859969/5845908 [=======================>......] - ETA: 14684s - loss: 0.07634860000\n4869955/5845908 [=======================>......] - ETA: 14535s - loss: 0.07634870000\n4879919/5845908 [========================>.....] - ETA: 14387s - loss: 0.07634880000\n4889960/5845908 [========================>.....] - ETA: 14238s - loss: 0.07624890000\n4899933/5845908 [========================>.....] - ETA: 14090s - loss: 0.07624900000\n4909931/5845908 [========================>.....] - ETA: 13941s - loss: 0.07624910000\n4919987/5845908 [========================>.....] - ETA: 13792s - loss: 0.07624920000\n4929984/5845908 [========================>.....] - ETA: 13644s - loss: 0.07614930000\n4939910/5845908 [========================>.....] - ETA: 13496s - loss: 0.07614940000\n4949974/5845908 [========================>.....] - ETA: 13346s - loss: 0.07614950000\n4959938/5845908 [========================>.....] - ETA: 13197s - loss: 0.07614960000\n4969971/5845908 [========================>.....] - ETA: 13048s - loss: 0.07604970000\n4979922/5845908 [========================>.....] - ETA: 12900s - loss: 0.07604980000\n4989971/5845908 [========================>.....] - ETA: 12750s - loss: 0.07604990000\n4999918/5845908 [========================>.....] - ETA: 12601s - loss: 0.07605000000\n5009907/5845908 [========================>.....] - ETA: 12453s - loss: 0.07595010000\n5019902/5845908 [========================>.....] - ETA: 12303s - loss: 0.07595020000\n5029899/5845908 [========================>.....] - ETA: 12154s - loss: 0.07595030000\n5039942/5845908 [========================>.....] - ETA: 12005s - loss: 0.07595040000\n5049913/5845908 [========================>.....] - ETA: 11856s - loss: 0.07585050000\n5059956/5845908 [========================>.....] - ETA: 11706s - loss: 0.07585060000\n5069943/5845908 [=========================>....] - ETA: 11557s - loss: 0.07585070000\n5079951/5845908 [=========================>....] - ETA: 11408s - loss: 0.07585080000\n5089931/5845908 [=========================>....] - ETA: 11259s - loss: 0.07575090000\n5099984/5845908 [=========================>....] - ETA: 11109s - loss: 0.07575100000\n5109942/5845908 [=========================>....] - ETA: 10961s - loss: 0.07575110000\n5119925/5845908 [=========================>....] - ETA: 10812s - loss: 0.07575120000\n5129962/5845908 [=========================>....] - ETA: 10662s - loss: 0.07565130000\n5139903/5845908 [=========================>....] - ETA: 10514s - loss: 0.07565140000\n5149895/5845908 [=========================>....] - ETA: 10365s - loss: 0.07565150000\n5159973/5845908 [=========================>....] - ETA: 10215s - loss: 0.07565160000\n5169965/5845908 [=========================>....] - ETA: 10066s - loss: 0.07555170000\n5179951/5845908 [=========================>....] - ETA: 9917s - loss: 0.07555180000\n5189972/5845908 [=========================>....] - ETA: 9768s - loss: 0.07555190000\n5199932/5845908 [=========================>....] - ETA: 9619s - loss: 0.07555200000\n5209903/5845908 [=========================>....] - ETA: 9471s - loss: 0.07545210000\n5219981/5845908 [=========================>....] - ETA: 9321s - loss: 0.07545220000\n5229919/5845908 [=========================>....] - ETA: 9173s - loss: 0.07545230000\n5239982/5845908 [=========================>....] - ETA: 9023s - loss: 0.07545240000\n5249910/5845908 [=========================>....] - ETA: 8875s - loss: 0.07535250000\n5259928/5845908 [=========================>....] - ETA: 8726s - loss: 0.07535260000\n5269966/5845908 [==========================>...] - ETA: 8576s - loss: 0.07535270000\n5279977/5845908 [==========================>...] - ETA: 8427s - loss: 0.07535280000\n5289913/5845908 [==========================>...] - ETA: 8279s - loss: 0.07525290000\n5299996/5845908 [==========================>...] - ETA: 8129s - loss: 0.07525300000\n5309924/5845908 [==========================>...] - ETA: 7981s - loss: 0.07525310000\n5319985/5845908 [==========================>...] - ETA: 7831s - loss: 0.07525320000\n5329944/5845908 [==========================>...] - ETA: 7683s - loss: 0.07525330000\n5339965/5845908 [==========================>...] - ETA: 7534s - loss: 0.07515340000\n5349941/5845908 [==========================>...] - ETA: 7385s - loss: 0.07515350000\n5359976/5845908 [==========================>...] - ETA: 7236s - loss: 0.07515360000\n5369907/5845908 [==========================>...] - ETA: 7088s - loss: 0.07515370000\n5379929/5845908 [==========================>...] - ETA: 6939s - loss: 0.07505380000\n5389992/5845908 [==========================>...] - ETA: 6789s - loss: 0.07505390000\n5399936/5845908 [==========================>...] - ETA: 6641s - loss: 0.07505400000\n5409978/5845908 [==========================>...] - ETA: 6491s - loss: 0.07505410000\n5419969/5845908 [==========================>...] - ETA: 6342s - loss: 0.07505420000\n5429914/5845908 [==========================>...] - ETA: 6194s - loss: 0.07495430000\n5439901/5845908 [==========================>...] - ETA: 6045s - loss: 0.07495440000\n5449956/5845908 [==========================>...] - ETA: 5896s - loss: 0.07495450000\n5459912/5845908 [===========================>..] - ETA: 5747s - loss: 0.07495460000\n5469995/5845908 [===========================>..] - ETA: 5597s - loss: 0.07485470000\n5479915/5845908 [===========================>..] - ETA: 5449s - loss: 0.07485480000\n5489977/5845908 [===========================>..] - ETA: 5299s - loss: 0.07485490000\n5499965/5845908 [===========================>..] - ETA: 5151s - loss: 0.07485500000\n5509940/5845908 [===========================>..] - ETA: 5002s - loss: 0.07475510000\n5519974/5845908 [===========================>..] - ETA: 4853s - loss: 0.07475520000\n5529915/5845908 [===========================>..] - ETA: 4705s - loss: 0.07475530000\n5539924/5845908 [===========================>..] - ETA: 4556s - loss: 0.07475540000\n5549953/5845908 [===========================>..] - ETA: 4406s - loss: 0.07475550000\n5559971/5845908 [===========================>..] - ETA: 4257s - loss: 0.07465560000\n5569904/5845908 [===========================>..] - ETA: 4109s - loss: 0.07465570000\n5579979/5845908 [===========================>..] - ETA: 3959s - loss: 0.07465580000\n5589904/5845908 [===========================>..] - ETA: 3811s - loss: 0.07465590000\n5599985/5845908 [===========================>..] - ETA: 3661s - loss: 0.07455600000\n5609923/5845908 [===========================>..] - ETA: 3513s - loss: 0.07455610000\n5619965/5845908 [===========================>..] - ETA: 3363s - loss: 0.07455620000\n5629964/5845908 [===========================>..] - ETA: 3214s - loss: 0.07455630000\n5639943/5845908 [===========================>..] - ETA: 3066s - loss: 0.07455640000\n5649926/5845908 [===========================>..] - ETA: 2917s - loss: 0.07445650000\n5659951/5845908 [============================>.] - ETA: 2769s - loss: 0.07445660000\n5669915/5845908 [============================>.] - ETA: 2621s - loss: 0.07445670000\n5679993/5845908 [============================>.] - ETA: 2472s - loss: 0.07445680000\n5689949/5845908 [============================>.] - ETA: 2324s - loss: 0.07435690000\n5699900/5845908 [============================>.] - ETA: 2176s - loss: 0.07435700000\n5709954/5845908 [============================>.] - ETA: 2026s - loss: 0.07435710000\n5719944/5845908 [============================>.] - ETA: 1877s - loss: 0.07435720000\n5729899/5845908 [============================>.] - ETA: 1729s - loss: 0.07425730000\n5739986/5845908 [============================>.] - ETA: 1578s - loss: 0.07425740000\n5749898/5845908 [============================>.] - ETA: 1431s - loss: 0.07425750000\n5759985/5845908 [============================>.] - ETA: 1280s - loss: 0.07425760000\n5769988/5845908 [============================>.] - ETA: 1131s - loss: 0.07415770000\n5779941/5845908 [============================>.] - ETA: 983s - loss: 0.07415780000\n5789998/5845908 [============================>.] - ETA: 833s - loss: 0.07415790000\n5799981/5845908 [============================>.] - ETA: 685s - loss: 0.07415800000\n5809916/5845908 [============================>.] - ETA: 537s - loss: 0.07415810000\n5819989/5845908 [============================>.] - ETA: 386s - loss: 0.07405820000\n5829908/5845908 [============================>.] - ETA: 238s - loss: 0.07405830000\n5839951/5845908 [============================>.] - ETA: 88s - loss: 0.07405840000\n5845829/5845908 [============================>.] - ETA: 1s - loss: 0.0740('Samples seen:', 1061092376)\nTraining completed!\nSaving model...\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 18, "cell_type": "code", "source": "# takes 24 housrs", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 19, "cell_type": "code", "source": "print(\"It's test time!\")\n\n# recover the embedding weights trained with skipgram:\nweights = model.layers[0].get_weights()[0]", "outputs": [{"output_type": "stream", "name": "stdout", "text": "It's test time!\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 20, "cell_type": "code", "source": "weights[:skip_top] = np.zeros((skip_top, dim_proj))\nnorm_weights = np_utils.normalize(weights)\n\nword_index = tokenizer.word_index\nreverse_word_index = dict([(v, k) for k, v in list(word_index.items())])\nword_index = tokenizer.word_index", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 22, "cell_type": "code", "source": "def embed_word(w):\n    i = word_index.get(w)\n    if (not i) or (i<skip_top) or (i>=max_features):\n        return None\n    return norm_weights[i]\n\ndef closest_to_point(point, nb_closest=10):\n    proximities = np.dot(norm_weights, point)\n    tups = list(zip(list(range(len(proximities))), proximities))\n    tups.sort(key=lambda x: x[1], reverse=True)\n    return [(reverse_word_index.get(t[0]), t[1]) for t in tups[:nb_closest]]  \n\ndef closest_to_word(w, nb_closest=10):\n    i = word_index.get(w)\n    if (not i) or (i<skip_top) or (i>=max_features):\n        return []\n    return closest_to_point(norm_weights[i].T, nb_closest)", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 23, "cell_type": "code", "source": "''' the resuls in comments below were for: \n    5.8M HN comments\n    dim_proj = 256\n    nb_epoch = 2\n    optimizer = rmsprop\n    loss = mse\n    max_features = 50000\n    skip_top = 100\n    negative_samples = 1.\n    window_size = 4\n    and frequency subsampling of factor 10e-5. \n'''\n\nwords = [\"article\", # post, story, hn, read, comments\n\"3\", # 6, 4, 5, 2\n\"two\", # three, few, several, each\n\"great\", # love, nice, working, looking\n\"data\", # information, memory, database\n\"money\", # company, pay, customers, spend\n\"years\", # ago, year, months, hours, week, days\n\"android\", # ios, release, os, mobile, beta\n\"javascript\", # js, css, compiler, library, jquery, ruby\n\"look\", # looks, looking\n\"business\", # industry, professional, customers\n\"company\", # companies, startup, founders, startups\n\"after\", # before, once, until\n\"own\", # personal, our, having\n\"us\", # united, country, american, tech, diversity, usa, china, sv\n\"using\", # javascript, js, tools (lol)\n\"here\", # hn, post, comments\n]\n\nfor w in words:\n    res = closest_to_word(w)\n    print('====', w)\n    for r in res:\n        print(r)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "('====', 'article')\n('article', 1.0000002)\n('post', 0.90891558)\n('story', 0.89286608)\n('posted', 0.89106327)\n('here', 0.8900885)\n('comments', 0.88936681)\n('reddit', 0.88504016)\n('pg', 0.88066208)\n('posts', 0.87696922)\n('thread', 0.87472731)\n('====', '3')\n('3', 0.99999988)\n('6', 0.94339204)\n('9', 0.94330382)\n('2', 0.94284344)\n('ff', 0.93928117)\n('32', 0.93828988)\n('24', 0.93781793)\n('7', 0.93774015)\n('36', 0.93521035)\n('released', 0.93484235)\n('====', 'two')\n('two', 1.0)\n('typically', 0.93890905)\n('quantity', 0.93832433)\n('defining', 0.93728578)\n('sustain', 0.93695474)\n('evolve', 0.93685579)\n('letting', 0.93666261)\n('dying', 0.93665802)\n('generations', 0.93659782)\n('avoiding', 0.93625355)\n('====', 'great')\n('great', 1.0)\n('looking', 0.93422735)\n('tell', 0.93256807)\n('posting', 0.93174744)\n('wish', 0.92921531)\n('helpful', 0.92886698)\n('informative', 0.92884183)\n('cool', 0.92871445)\n('idea', 0.92823637)\n('fun', 0.92710769)\n('====', 'data')\n('data', 1.0000002)\n('storage', 0.90516901)\n('storing', 0.90049845)\n('hashing', 0.89902455)\n('implemented', 0.89745152)\n('caching', 0.89728582)\n('encrypted', 0.89696115)\n('methods', 0.89646441)\n('simple', 0.89602488)\n('plaintext', 0.89597952)\n('====', 'money')\n('money', 1.0)\n('companies', 0.93026137)\n('company', 0.92494476)\n('customers', 0.92021573)\n('paying', 0.91961157)\n('likely', 0.91767448)\n('spending', 0.91637743)\n('employees', 0.91532087)\n('investment', 0.91492891)\n('pay', 0.91452479)\n('====', 'years')\n('years', 1.0)\n('months', 0.94392097)\n('past', 0.93173051)\n('week', 0.92992276)\n('minutes', 0.92972291)\n('spent', 0.92907798)\n('hours', 0.92837012)\n('couple', 0.9270919)\n('consensus', 0.92708981)\n('weeks', 0.92601526)\n('====', 'android')\n('android', 0.99999988)\n('ios', 0.94578266)\n('features', 0.93861037)\n('tablet', 0.93838167)\n('desktop', 0.93774199)\n('ipad', 0.93726087)\n('oses', 0.93691599)\n('platforms', 0.93657035)\n('ported', 0.9364593)\n('apps', 0.93606949)\n('====', 'javascript')\n('javascript', 0.99999988)\n('jquery', 0.93641472)\n('using', 0.93390918)\n('code', 0.93197763)\n('browser', 0.92690337)\n('default', 0.92589772)\n('css', 0.92425084)\n('server', 0.92361653)\n('ajax', 0.92300272)\n('plugins', 0.91980928)\n('====', 'look')\n('look', 0.99999982)\n('wanted', 0.94779706)\n('helpful', 0.94502401)\n('excited', 0.94429147)\n('write', 0.94348037)\n('suggestions', 0.94347084)\n('nicer', 0.9432714)\n('option', 0.9431746)\n('exact', 0.94313562)\n('easiest', 0.94311738)\n('====', 'business')\n('business', 1.0)\n('businesses', 0.93864095)\n('company', 0.9364717)\n('education', 0.93593216)\n('entrepreneurs', 0.93444502)\n('spending', 0.93438578)\n('competitive', 0.9330337)\n('startups', 0.93302143)\n('technical', 0.93276441)\n('companies', 0.93249726)\n('====', 'company')\n('company', 1.0)\n('companies', 0.95230079)\n('spending', 0.94772577)\n('spend', 0.94633341)\n('willing', 0.945072)\n('employees', 0.94389528)\n('situation', 0.94301093)\n('businesses', 0.94213593)\n('paying', 0.94121146)\n('benefit', 0.94106424)\n('====', 'after')\n('after', 1.0000004)\n('whatsapp', 0.9372161)\n('shipped', 0.93622434)\n('consoles', 0.93525684)\n('invites', 0.93461001)\n('mins', 0.93418413)\n('hits', 0.93370008)\n('showdead', 0.93312764)\n('requested', 0.93279946)\n('five', 0.93275297)\n('====', 'own')\n('own', 0.99999976)\n('worthwhile', 0.95177341)\n('reward', 0.95115095)\n('contribution', 0.95105624)\n('matters', 0.95075196)\n('expertise', 0.94946122)\n('complicated', 0.94895703)\n('incentive', 0.94894111)\n('fixing', 0.94872379)\n('necessarily', 0.94861817)\n('====', 'us')\n('us', 0.99999982)\n('eu', 0.92610723)\n('usa', 0.92355561)\n('berlin', 0.92285001)\n('nations', 0.92176247)\n('mexico', 0.91843802)\n('guardian', 0.91689533)\n('indian', 0.91606253)\n('visited', 0.91603446)\n('international', 0.9155103)\n('====', 'using')\n('using', 1.0)\n('javascript', 0.93390918)\n('css', 0.92669106)\n('flash', 0.92400962)\n('uses', 0.9220047)\n('jquery', 0.92187738)\n('ajax', 0.92156923)\n('supports', 0.92156422)\n('server', 0.92112899)\n('browser', 0.92078733)\n('====', 'here')\n('here', 1.0000001)\n('thread', 0.93336034)\n('post', 0.93085027)\n('posted', 0.92966461)\n('posting', 0.92936492)\n('pg', 0.92331135)\n('hacker', 0.92293847)\n('posts', 0.92182922)\n('interesting', 0.92130566)\n('hn', 0.92033947)\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 25, "cell_type": "code", "source": "closest_to_word('book')", "outputs": [{"execution_count": 25, "output_type": "execute_result", "data": {"text/plain": "[('book', 0.99999988),\n ('books', 0.93772721),\n ('tutorial', 0.9375813),\n ('paywall', 0.93704069),\n ('intro', 0.93491739),\n ('screenshots', 0.93375456),\n ('redirects', 0.9337393),\n ('favorite', 0.93335485),\n ('repo', 0.93316227),\n ('ff', 0.9330492)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 27, "cell_type": "code", "source": "closest_to_word('paypal')", "outputs": [{"execution_count": 27, "output_type": "execute_result", "data": {"text/plain": "[('paypal', 0.99999976),\n ('stripe', 0.94726515),\n ('listing', 0.94713485),\n ('doge', 0.94603837),\n ('belongs', 0.94497705),\n ('coinbase', 0.94476163),\n ('automating', 0.94357979),\n ('3gs', 0.94293594),\n ('heartbleed', 0.9426229),\n ('placement', 0.94246304)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 29, "cell_type": "code", "source": "closest_to_word('iphone')", "outputs": [{"execution_count": 29, "output_type": "execute_result", "data": {"text/plain": "[('iphone', 1.0),\n ('ipad', 0.93695891),\n ('mac', 0.93089706),\n ('android', 0.92847413),\n ('osx', 0.92499757),\n ('mobile', 0.9189598),\n ('desktop', 0.9188664),\n ('kindle', 0.91885668),\n ('app', 0.9180249),\n ('ios', 0.91645032)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 30, "cell_type": "code", "source": "closest_to_word('samsung')", "outputs": [{"execution_count": 30, "output_type": "execute_result", "data": {"text/plain": "[('samsung', 1.0000002),\n ('nexus', 0.94058442),\n ('htc', 0.93408191),\n ('motorola', 0.93351519),\n ('shipped', 0.93209493),\n ('droid', 0.92996943),\n ('shows', 0.92826527),\n ('contains', 0.9279933),\n ('salesforce', 0.92773867),\n ('gem', 0.92740226)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 31, "cell_type": "code", "source": "closest_to_word('obama')", "outputs": [{"execution_count": 31, "output_type": "execute_result", "data": {"text/plain": "[('obama', 0.99999988),\n ('clinton', 0.91198832),\n ('cue', 0.90583628),\n ('florida', 0.90488577),\n ('screencasts', 0.90177119),\n ('pending', 0.90155625),\n ('hits', 0.90109777),\n ('putin', 0.9001627),\n ('groupon', 0.90015745),\n ('esp', 0.90002215)]"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}