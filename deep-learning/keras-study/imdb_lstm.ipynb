{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a LSTM on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage \n",
    "compared to simpler, much faster methods such as TF-IDF+LogReg.\n",
    "Notes: \n",
    "- RNNs are tricky. Choice of batch size is important, \n",
    "choice of loss and optimizer is critical, etc. \n",
    "Most configurations won't converge.\n",
    "- LSTM loss decrease during training can be quite different \n",
    "from what you see with CNNs/MLPs/etc. It's more or less a sigmoid\n",
    "instead of an inverse exponential.\n",
    "GPU command:\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py\n",
    "250s/epoch on GPU (GT 650M), vs. 400s/epoch on CPU (2.4Ghz Core i7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features=20000\n",
    "maxlen = 100 # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 train sequences\n",
      "5000 test sequences\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features, test_split=0.2)\n",
    "print len(X_train), 'train sequences'\n",
    "print len(X_test), 'test sequences' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 10, 2, 257, 7, 25, 18, 69, 4195, 1513, 16, 121, 41, 2, 73, 3, 26, 14, 20, 33, 1758, 303, 4, 16, 75, 121, 14, 299, 15, 6, 153, 8, 112, 263, 18, 14, 20, 22, 96, 22, 16, 101, 219, 14, 21, 4, 12, 13, 9, 11, 12, 13, 9, 11, 61, 257, 7, 10886, 17974, 6, 15138, 13325, 4, 29, 18, 3, 42, 238, 3, 10, 45, 4874, 146, 272, 15138, 17974, 6, 62, 191, 7, 2, 17832, 4, 28, 2, 4570, 281, 206, 15, 2, 0, 6009, 5, 8198, 0, 8, 2, 19456, 3, 6, 257, 7, 0, 8062, 4, 12, 13, 9, 11, 12, 13, 9, 11, 14, 56, 39, 7, 163, 10355, 5908, 3, 2, 407, 357, 1437, 53, 1201, 768, 2, 9732, 4, 12, 13, 9, 11, 12, 13, 9, 11, 19, 81, 196, 31, 275, 218, 40, 19, 3, 561, 1789, 695, 10872, 4, 34, 10, 48, 222, 4, 558, 23, 727, 3982, 4, 34, 20, 15, 41, 149, 1699, 116, 4, 12, 13, 9, 11, 12, 13, 9, 11, 121, 174, 25, 318, 4, 470, 3, 33, 19, 4562, 19, 2, 216, 4, 18, 20, 70, 62, 357, 4, 318, 3, 121, 6, 553, 526, 55, 1573, 16582, 49, 19, 2839, 7, 2, 7106, 4, 19]\n",
      "216\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]\n",
    "print len(X_train[0])\n",
    "print y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (20000, 100)\n",
      "X_test shape: (5000, 100)\n"
     ]
    }
   ],
   "source": [
    "print \"Pad sequences (samples x time)\"\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print 'X_train shape:', X_train.shape\n",
    "print 'X_test shape:', X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   17    10     2   257     7    25    18    69  4195  1513    16   121\n",
      "    41     2    73     3    26    14    20    33  1758   303     4    16\n",
      "    75   121    14   299    15     6   153     8   112   263    18    14\n",
      "    20    22    96    22    16   101   219    14    21     4    12    13\n",
      "     9    11    12    13     9    11    61   257     7 10886 17974     6\n",
      " 15138 13325     4    29    18     3    42   238     3    10    45  4874\n",
      "   146   272 15138 17974     6    62   191     7     2 17832     4    28\n",
      "     2  4570   281   206    15     2     0  6009     5  8198     0     8\n",
      "     2 19456     3     6]\n",
      "(20000, 100)\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 256))\n",
    "model.add(LSTM(256, 128)) # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikien/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 0\n",
      "18000/18000 [==============================] - 724s - loss: 0.6319 - acc.: 0.6557 - val. loss: 0.5908 - val. acc.: 0.7090\n",
      "Epoch 1\n",
      "18000/18000 [==============================] - 729s - loss: 0.4278 - acc.: 0.8183 - val. loss: 0.4212 - val. acc.: 0.8130\n",
      "Epoch 2\n",
      "18000/18000 [==============================] - 713s - loss: 0.2875 - acc.: 0.8902 - val. loss: 0.3895 - val. acc.: 0.8430\n",
      "Epoch 3\n",
      "18000/18000 [==============================] - 706s - loss: 0.2500 - acc.: 0.9041 - val. loss: 0.4578 - val. acc.: 0.8185\n",
      "Epoch 4\n",
      "18000/18000 [==============================] - 719s - loss: 0.1572 - acc.: 0.9478 - val. loss: 0.5186 - val. acc.: 0.8370\n",
      "5000/5000 [==============================] - 19s - loss: 0.5982    \n",
      "Test score: 0.598056177763\n"
     ]
    }
   ],
   "source": [
    "print \"Train...\"\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=5, validation_split=0.1, show_accuracy=True)\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print 'Test score:', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 21s    \n",
      "Test accuracy: 0.809\n"
     ]
    }
   ],
   "source": [
    "classes = model.predict_classes(X_test, batch_size=batch_size)\n",
    "acc = np_utils.accuracy(classes, y_test)\n",
    "print 'Test accuracy:', acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
